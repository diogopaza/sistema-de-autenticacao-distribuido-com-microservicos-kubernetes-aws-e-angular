Sistema de AutenticaÃ§Ã£o DistribuÃ­do com MicroserviÃ§os, Kubernetes, AWS e Angular
ğŸ¯ Objetivo do Projeto

Este projeto tem como objetivo projetar, implementar e operar um sistema de autenticaÃ§Ã£o e autorizaÃ§Ã£o distribuÃ­do, utilizando arquitetura de microserviÃ§os executando nativamente em Kubernetes, com foco em seguranÃ§a, escalabilidade, resiliÃªncia e prÃ¡ticas reais de produÃ§Ã£o.

Mais do que entregar um sistema funcional, este exercÃ­cio foi concebido para simular um cenÃ¡rio real de mercado, no qual decisÃµes arquiteturais, trade-offs tÃ©cnicos e maturidade na operaÃ§Ã£o da aplicaÃ§Ã£o sÃ£o tÃ£o importantes quanto o cÃ³digo em si.

O sistema contempla desde a concepÃ§Ã£o da arquitetura, passando pela execuÃ§Ã£o prÃ¡tica em Kubernetes desde o primeiro dia, atÃ© deploy real em AWS (EKS), testes automatizados, CI/CD, observabilidade e integraÃ§Ã£o com frontend.

ğŸ§  PropÃ³sito do ExercÃ­cio

Este nÃ£o Ã© um projeto de â€œhello worldâ€, nem um CRUD simples.

O propÃ³sito Ã© demonstrar, na prÃ¡tica:

Como pensar aplicaÃ§Ãµes cloud-native desde a arquitetura

Como projetar microserviÃ§os independentes, escalÃ¡veis e seguros

Como usar o Kubernetes como plataforma, e nÃ£o apenas como um repositÃ³rio de YAML

Como separar corretamente responsabilidades, configuraÃ§Ã£o e segredos

Como lidar com seguranÃ§a moderna (JWT, autorizaÃ§Ã£o granular)

Como preparar o sistema para alto volume transacional

Como operar tudo isso em um ambiente prÃ³ximo ao real (AWS)

Cada etapa do projeto foi pensada para forÃ§ar decisÃµes tÃ©cnicas conscientes, semelhantes Ã s enfrentadas no dia a dia de times de engenharia em produÃ§Ã£o.

ğŸ—ï¸ VisÃ£o Geral da SoluÃ§Ã£o

A soluÃ§Ã£o consiste em um ecossistema de microserviÃ§os, incluindo:

ServiÃ§os de autenticaÃ§Ã£o e gerenciamento de usuÃ¡rios

Gateway como ponto Ãºnico de entrada

Descoberta de serviÃ§os e configuraÃ§Ã£o centralizada

ComunicaÃ§Ã£o sÃ­ncrona e assÃ­ncrona entre serviÃ§os

PersistÃªncia isolada por serviÃ§o

Frontend Angular consumindo a API via Gateway

Todo o sistema Ã© executado exclusivamente dentro de Kubernetes, desde os primeiros testes atÃ© o deploy final em AWS EKS, garantindo consistÃªncia entre ambientes e eliminando o clÃ¡ssico â€œfunciona na minha mÃ¡quinaâ€.

ğŸš€ Foco Principal

O foco deste projeto estÃ¡ em:

Arquitetura distribuÃ­da

ExecuÃ§Ã£o real em Kubernetes

SeguranÃ§a e autorizaÃ§Ã£o

Escalabilidade e resiliÃªncia

Testes automatizados

Observabilidade

Cloud (AWS)

Boas prÃ¡ticas de produÃ§Ã£o

O cÃ³digo Ã© importante â€” mas a forma como o sistema Ã© projetado, testado, escalado e operado Ã© o verdadeiro objeto de avaliaÃ§Ã£o.

ğŸ“Œ Resultado Esperado

Ao final do exercÃ­cio, o projeto deve representar um sistema:

ExecutÃ¡vel em Kubernetes desde o inÃ­cio

Seguro, stateless e escalÃ¡vel

Preparado para falhas e alto volume de requisiÃ§Ãµes

Automatizado via CI/CD

Implantado em ambiente cloud real

Documentado com clareza sobre decisÃµes tÃ©cnicas

Este exercÃ­cio se posiciona como um projeto de nÃ­vel Pleno forte a SÃªnior inicial, alinhado com prÃ¡ticas exigidas no mercado atual.

ğŸ§  PERFIL AVALIADO

Este exercÃ­cio avalia:

Arquitetura de software

Backend com Java / Spring

Kubernetes real (nÃ£o apenas YAML bÃ¡sico)

SeguranÃ§a

NOVA ETAPA â€” AUTORIZAÃ‡ÃƒO GRANULAR

Testes automatizados

ComunicaÃ§Ã£o entre serviÃ§os

CI/CD

Cloud (AWS)

IntegraÃ§Ã£o com frontend

â±ï¸ CRONOGRAMA GERAL

DuraÃ§Ã£o total: 6 semanas (â‰ˆ 45â€“50 dias)

Semana	Foco principal
1	Arquitetura + Kubernetes desde o inÃ­cio
2	MicroserviÃ§os + ConfiguraÃ§Ã£o + SeguranÃ§a
3	Kubernetes intermediÃ¡rio + Testes
4	Frontend + Observabilidade
5	AWS (EKS)
6	CI/CD + Hardening
ğŸ”¹ ETAPA 0 â€” ARQUITETURA ORIENTADA A KUBERNETES

ğŸ“… Dias 1 a 3

Objetivo

Pensar o sistema como algo que sempre rodarÃ¡ em Kubernetes.

Entregas

Documento (README ou markdown) explicando:

visÃ£o geral do sistema

responsabilidades dos serviÃ§os

por que microserviÃ§os

por que Kubernetes

Diagrama contendo:

Pods

Services

ConfigMaps

Secrets

Gateway

CritÃ©rios de avaliaÃ§Ã£o

Clareza de comunicaÃ§Ã£o

DecisÃµes bem justificadas

ConsistÃªncia com ambiente distribuÃ­do

ğŸ”¹ ETAPA 1 â€” KUBERNETES LOCAL (BASE REAL)

ğŸ“… Dias 4 a 7

Objetivo

Ter Kubernetes funcionando antes do cÃ³digo de negÃ³cio.

Entregas

Cluster local (Minikube ou Docker Desktop)

Primeiro Pod (nginx ou app simples)

Services:

ClusterIP

NodePort

Testes:

kubectl exec

kubectl logs

kubectl describe

kubectl port-forward

Conceitos obrigatÃ³rios

Pod â‰  Container

Service â‰  IP fixo

DNS interno do Kubernetes

ğŸ“¦ ETAPA 2 â€” MICROSSERVIÃ‡OS BASE (SPRING)

ğŸ“… Dias 8 a 11

ğŸ¯ Objetivo

Ter a arquitetura de microsserviÃ§os funcional, rodando exclusivamente dentro do Kubernetes, sem foco ainda em regras de negÃ³cio complexas.

âš ï¸ Regra-chave de avaliaÃ§Ã£o
Se roda fora do Kubernetes, mas nÃ£o roda dentro, nÃ£o estÃ¡ pronto.

ğŸ”¹ ServiÃ§os obrigatÃ³rios
ServiÃ§o	Responsabilidade
eureka-server	Service Discovery
config-server	ConfiguraÃ§Ã£o centralizada
api-gateway	Ponto Ãºnico de entrada
auth-service	AutenticaÃ§Ã£o
user-service	Gerenciamento de usuÃ¡rios
ğŸ”¹ Entregas obrigatÃ³rias (para cada serviÃ§o)

Cada serviÃ§o deve conter:

Spring Boot

Porta configurÃ¡vel via variÃ¡vel de ambiente

Endpoint:

/actuator/health


Dockerfile funcional

Deployment Kubernetes

Service Kubernetes (ClusterIP)

ğŸ”¹ Testes esperados
kubectl get pods
kubectl get svc
kubectl logs <pod>
kubectl exec <pod>
curl http://<service>:<port>/actuator/health


âœ” Todos os serviÃ§os Running
âœ” ComunicaÃ§Ã£o via DNS interno do Kubernetes

ğŸ”¹ AvaliaÃ§Ã£o

Arquitetura correta

ServiÃ§os desacoplados

Nada rodando fora do cluster

Gateway chamando serviÃ§os via nome DNS

ğŸ”¹ NOVA ETAPA (DIFERENCIAL) â€” MICRONAUT (SEM SUBSTITUIR SPRING)

ğŸ“ Onde entra:
â¡ï¸ ApÃ³s ETAPA 2 â€” MICROSSERVIÃ‡OS BASE
â¡ï¸ Antes de SeguranÃ§a

ğŸ’¡ Importante:

NÃ£o substitui Spring

NÃ£o reescreve tudo

Serve para comparaÃ§Ã£o arquitetural + maturidade tÃ©cnica

ğŸ¯ Objetivo da etapa Micronaut

Demonstrar:

Conhecimento de framework alternativo

Entendimento de build-time DI

DiferenÃ§a real entre Spring x Micronaut em Kubernetes

ğŸ”¹ O que serÃ¡ feito (escopo enxuto)

Criar um novo microserviÃ§o auxiliar, por exemplo:

audit-service (Micronaut)

Responsabilidade:

Receber eventos (ex: login, criaÃ§Ã£o de usuÃ¡rio)

Persistir logs/auditoria

NÃƒO participa da autenticaÃ§Ã£o diretamente

ğŸ‘‰ Isso evita mexer no fluxo crÃ­tico.

ğŸ”¹ ImplementaÃ§Ã£o Micronaut (prÃ¡tica)
1ï¸âƒ£ Criar projeto Micronaut
mn create-app audit-service \
  --lang=java \
  --build=maven

2ï¸âƒ£ Endpoint simples
@Controller("/audit")
public class AuditController {

    @Post
    public HttpResponse<?> log(@Body AuditEvent event) {
        return HttpResponse.ok();
    }
}

3ï¸âƒ£ Dockerfile
FROM eclipse-temurin:17-jre
COPY target/audit-service.jar app.jar
ENTRYPOINT ["java","-jar","/app.jar"]

4ï¸âƒ£ Kubernetes

Deployment

Service (ClusterIP)

Porta via env

env:
- name: MICRONAUT_SERVER_PORT
  value: "8080"

ğŸ”¹ IntegraÃ§Ã£o com Spring

No auth-service ou user-service:

restTemplate.postForEntity(
  "http://audit-service/audit",
  payload,
  Void.class
);


ğŸ‘‰ Via DNS interno Kubernetes, exatamente como os outros.

ğŸ”¹ Testes (Micronaut)
Teste unitÃ¡rio
@MicronautTest
class AuditControllerTest {

    @Test
    void shouldAcceptAuditEvent() {
        // assert status 200
    }
}

Teste em Kubernetes
kubectl get pods
kubectl logs audit-service
kubectl exec test-pod -- curl http://audit-service/audit

ğŸ”¹ AvaliaÃ§Ã£o (Micronaut)

âœ” ServiÃ§o Micronaut rodando no Kubernetes
âœ” ComunicaÃ§Ã£o Spring â†’ Micronaut
âœ” Justificativa clara no README:

Micronaut foi utilizado para demonstrar alternativa cloud-native com injeÃ§Ã£o de dependÃªncia em tempo de compilaÃ§Ã£o, reduzindo consumo de memÃ³ria e tempo de startup, especialmente relevante para workloads escalÃ¡veis em Kubernetes.

ğŸ“¦ ETAPA 3 â€” CONFIGURAÃ‡ÃƒO CENTRALIZADA

(Spring Cloud Config + Kubernetes)

ğŸ“… Dias 12 a 14

ğŸ¯ Objetivo

Separar cÃ³digo de configuraÃ§Ã£o, seguindo boas prÃ¡ticas de microsserviÃ§os.

ğŸ”¹ Entregas obrigatÃ³rias
Spring Cloud Config Server

ConfiguraÃ§Ãµes versionadas em Git

Perfis (dev, k8s, prod)

ConfigMaps (Kubernetes)

Usados para:

URLs de serviÃ§os

Portas

Perfis ativos

ConfiguraÃ§Ãµes nÃ£o sensÃ­veis

Exemplo:

SPRING_PROFILES_ACTIVE=k8s
EUREKA_CLIENT_SERVICEURL_DEFAULTZONE=http://eureka-server:8761/eureka

Secrets (Kubernetes)

Usados para:

Senhas

Tokens

Chaves JWT

Credenciais de banco

â— Nenhum segredo no application.yml

ğŸ”¹ Conceitos avaliados

SeparaÃ§Ã£o entre cÃ³digo e configuraÃ§Ã£o

Versionamento de config

SeguranÃ§a bÃ¡sica

Uso correto de ConfigMap vs Secret

ğŸ“¦ ETAPA 4 â€” SEGURANÃ‡A

(Spring Security + JWT)

ğŸ“… Dias 15 a 18

ğŸ¯ Objetivo

Implementar autenticaÃ§Ã£o moderna e stateless.

ğŸ”¹ Entregas obrigatÃ³rias

Login funcional (/auth/login)

JWT vÃ¡lido retornado

Gateway validando token

ServiÃ§os protegidos

Secrets injetados via Kubernetes

ğŸ”¹ Requisitos tÃ©cnicos

REST stateless

Nenhuma sessÃ£o em memÃ³ria

Token passado via:

Authorization: Bearer <token>

ğŸ”¹ AvaliaÃ§Ã£o

âœ” Token invÃ¡lido â†’ acesso negado
âœ” Token vÃ¡lido â†’ acesso permitido

ğŸ“¦ NOVA ETAPA â€” AUTORIZAÃ‡ÃƒO GRANULAR

(ApÃ³s SeguranÃ§a)

ğŸ“… Dias 19 a 20

ğŸ¯ Objetivo

Garantir que autenticaÃ§Ã£o â‰  autorizaÃ§Ã£o.

ğŸ”¹ Entregas obrigatÃ³rias
JWT contendo:

roles

scopes

Exemplo:

{
  "sub": "diogo",
  "roles": ["ADMIN"],
  "scopes": ["users.read", "users.write"]
}

Regras no Gateway
/admin/** â†’ ADMIN
/users/** â†’ USER

Regras nos serviÃ§os
@PreAuthorize("hasRole('ADMIN')")
@PreAuthorize("hasAuthority('users.read')")

ğŸ”¹ AvaliaÃ§Ã£o

Token vÃ¡lido â‰  acesso liberado

AutorizaÃ§Ã£o consistente:

Gateway

ServiÃ§o

ğŸ†• NOVA SUBSEÃ‡ÃƒO â€” AUDITORIA DE IP E USER-AGENT (NÃVEL SÃŠNIOR)
ğŸ¯ Objetivo

Demonstrar maturidade em seguranÃ§a, auditoria e rastreabilidade, garantindo que cada requisiÃ§Ã£o autenticada possa ser rastreada atÃ© sua origem, algo essencial em ambientes corporativos, financeiros e regulados.

ğŸ”¹ O que serÃ¡ implementado

Para todas as requisiÃ§Ãµes que passam pelo Gateway, o sistema irÃ¡:

Capturar o IP de origem do cliente

Capturar o User-Agent

Associar essas informaÃ§Ãµes ao usuÃ¡rio autenticado (JWT)

Tornar essas informaÃ§Ãµes disponÃ­veis para:

logs

auditoria

troubleshooting

investigaÃ§Ãµes de seguranÃ§a

ğŸ”¹ Pontos tÃ©cnicos avaliados
1ï¸âƒ£ Captura correta do IP real do cliente

Em ambientes com Gateway, Load Balancer e Kubernetes, o IP real nÃ£o estÃ¡ em request.getRemoteAddr().

O sistema considera corretamente os headers padrÃ£o de produÃ§Ã£o:

X-Forwarded-For

X-Real-IP

Com fallback controlado.

ğŸ“Œ DecisÃ£o tÃ©cnica documentada:
O IP Ã© extraÃ­do prioritariamente de X-Forwarded-For, considerando o primeiro IP da cadeia, conforme boas prÃ¡ticas em ambientes com proxy reverso.

2ï¸âƒ£ Captura do User-Agent

O header User-Agent Ã© capturado e armazenado para:

IdentificaÃ§Ã£o de cliente (browser, mobile, script)

DetecÃ§Ã£o de padrÃµes suspeitos

Auditoria de acessos

3ï¸âƒ£ PropagaÃ§Ã£o segura entre Gateway e serviÃ§os

O Gateway Ã© responsÃ¡vel por enriquecer a requisiÃ§Ã£o, adicionando headers internos:

X-Client-IP

X-Client-User-Agent

Esses headers:

NÃ£o sÃ£o confiÃ¡veis externamente

SÃ£o usados apenas dentro do cluster

Facilitam auditoria sem acoplamento ao Gateway

4ï¸âƒ£ Uso prÃ¡tico das informaÃ§Ãµes

As informaÃ§Ãµes de IP e User-Agent sÃ£o utilizadas em:

Logs estruturados

Eventos de auditoria (ex: login realizado)

IntegraÃ§Ã£o com o audit-service (Micronaut)

Exemplo de evento auditado:

{
  "user": "diogo",
  "action": "LOGIN_SUCCESS",
  "ip": "187.45.xxx.xxx",
  "userAgent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
  "timestamp": "2026-02-02T21:34:10Z"
}

ğŸ”¹ AvaliaÃ§Ã£o (nÃ­vel sÃªnior)

âœ” Entendimento de infraestrutura real (Gateway, proxy, Kubernetes)
âœ” NÃ£o confiar em IP direto da requisiÃ§Ã£o
âœ” SeparaÃ§Ã£o de responsabilidades (Gateway enriquece, serviÃ§o consome)
âœ” PreparaÃ§Ã£o para auditoria, seguranÃ§a e compliance
âœ” Arquitetura preparada para investigaÃ§Ã£o de incidentes

ğŸ—„ï¸ ETAPA EXTRA (AVANÃ‡ADA) â€” FLYWAY (VERSIONAMENTO DE BANCO)

ğŸ“… Inserida entre ETAPA 3 e ETAPA 4

ğŸ‘‰ Essa Ã© a melhor etapa para incluir Flyway, porque:

ConfiguraÃ§Ã£o jÃ¡ estÃ¡ centralizada

Secrets jÃ¡ existem

SeguranÃ§a ainda nÃ£o bloqueia fluxo

ğŸ¯ Objetivo

Garantir versionamento e controle do schema do banco, alinhado a microsserviÃ§os.

ğŸ”¹ Entregas obrigatÃ³rias
Flyway configurado em:

auth-service

user-service

Scripts de migraÃ§Ã£o
db/migration/
V1__create_users_table.sql
V2__add_roles_table.sql
V3__add_user_roles.sql

Banco rodando no Kubernetes

PostgreSQL ou MySQL

Credenciais via Secrets

URL via ConfigMap

ğŸ”¹ AvaliaÃ§Ã£o (nÃ­vel avanÃ§ado)

Schema criado automaticamente

MigraÃ§Ãµes idempotentes

Rollout sem perda de dados

Flyway executando ao subir o Pod

ğŸ”¹ ETAPA 5 â€” TESTES AUTOMATIZADOS (OBRIGATÃ“RIO)

ğŸ“… Dias 19 a 23

Objetivo

Garantir qualidade, seguranÃ§a e estabilidade.

ğŸ§ª EstratÃ©gia de Testes
ğŸ”¹ Testes UnitÃ¡rios

Regras de negÃ³cio

ServiÃ§os

ValidaÃ§Ã£o de token

Ferramentas:
JUnit 5, Mockito

ğŸ”¹ Testes de Controller

Endpoints REST

Status HTTP

SeguranÃ§a (401 / 403)

Ferramentas:
Spring MockMvc

ğŸ”¹ Testes de IntegraÃ§Ã£o

ComunicaÃ§Ã£o entre serviÃ§os

Config Server

Banco de dados

ğŸ§ª Testes de AutorizaÃ§Ã£o (OBRIGATÃ“RIO)
Exemplos:

UsuÃ¡rio sem role ADMIN tentando acessar endpoint admin â†’ 403

Token invÃ¡lido â†’ 401

Token vÃ¡lido + role correta â†’ 200

Ferramentas:
Spring Boot Test, Testcontainers

ğŸ”¹ Testes em Kubernetes

Simular restart de Pods

Validar self-healing

Testar comportamento com falhas

CritÃ©rio eliminatÃ³rio

âŒ Projeto sem testes nÃ£o passa

ğŸ”¹ ETAPA 6 â€” KUBERNETES INTERMEDIÃRIO

ğŸ“… Dias 24 a 27

Entregas

Deployments (nÃ£o Pods soltos)

RÃ©plicas

Rolling update

Teste de escalabilidade

Conceitos avaliados

Desired State

Self-healing

Escalonamento horizontal

ğŸ”¥ NOVA ETAPA (DIFERENCIAL AVANÃ‡ADO) â€” ALTO VOLUME TRANSACIONAL

ğŸ“ Onde entra:
â¡ï¸ ApÃ³s ETAPA 6 â€” Kubernetes IntermediÃ¡rio
â¡ï¸ Antes de AWS

ğŸ¯ Objetivo

Demonstrar que o sistema:

Suporta alta concorrÃªncia

Escala corretamente

MantÃ©m consistÃªncia

NÃ£o quebra sob carga

ğŸ”¹ O que serÃ¡ avaliado (bem objetivo)
ğŸ”¸ 1. Stateless real

Nenhuma sessÃ£o em memÃ³ria

JWT 100%

âœ” JÃ¡ estÃ¡ alinhado com seu projeto

ğŸ”¸ 2. Banco preparado para carga

ConfiguraÃ§Ãµes no Spring:

spring:
  datasource:
    hikari:
      maximum-pool-size: 20
      minimum-idle: 5

ğŸ”¸ 3. Teste de carga REAL

Usar k6 (simples e profissional)

import http from 'k6/http';

export let options = {
  vus: 100,
  duration: '30s',
};

export default function () {
  http.get('http://gateway/auth/health');
}


Rodar:

k6 run load-test.js

ğŸ”¹ Teste com Kubernetes (obrigatÃ³rio)
Escalonar serviÃ§o
kubectl scale deployment auth-service --replicas=3

Validar:
kubectl get pods
kubectl top pods


âœ” Requests distribuÃ­dos
âœ” Nenhum erro 5xx
âœ” Respostas < timeout

ğŸ”¹ Teste de falha (self-healing)
kubectl delete pod auth-service-xxxx


âœ” Novo Pod sobe
âœ” Sistema continua respondendo
âœ” Gateway redireciona corretamente

ğŸ”¹ MÃ©trica mÃ­nima exigida

No README:

CenÃ¡rio	Resultado
100 req/s	OK
Pod morto	Auto-recuperaÃ§Ã£o
3 rÃ©plicas	Load distribuÃ­do
ğŸ”¹ AvaliaÃ§Ã£o (Alto Volume)

âœ” Entendimento de concorrÃªncia
âœ” Escalonamento horizontal real
âœ” Testes prÃ¡ticos documentados
âœ” Kubernetes usado como plataforma, nÃ£o sÃ³ YAML

ğŸ”¹ ETAPA 7 â€” COMUNICAÃ‡ÃƒO ASSÃNCRONA

ğŸ“… Dias 28 a 30

Entregas

Evento de domÃ­nio (ex: usuÃ¡rio criado)

ServiÃ§o consumidor

SimulaÃ§Ã£o de falha

AvaliaÃ§Ã£o

Quando usar REST

Quando usar eventos

ğŸ”¹ ETAPA 8 â€” RESILIÃŠNCIA E OBSERVABILIDADE

ğŸ“… Dias 31 a 33

Entregas

Circuit Breaker

Actuator

Liveness e Readiness Probes

Logs estruturados

ğŸ”¹ ETAPA 9 â€” FRONTEND (ANGULAR)

ğŸ“… Dias 34 a 37

Telas obrigatÃ³rias

Login

Dashboard simples

Entregas

Interceptor JWT

ComunicaÃ§Ã£o via Gateway

Build containerizado

ğŸ”¹ ETAPA 10 â€” KUBERNETES AVANÃ‡ADO

ğŸ“… Dias 38 a 40

Entregas

Ingress Controller

Load balancing interno

DNS via Service

Teste com mÃºltiplas rÃ©plicas

ğŸ”¹ ETAPA 11 â€” AWS (EKS REAL)

ğŸ“… Dias 41 a 45

Entregas

Cluster EKS

Deploy completo

LoadBalancer AWS

Frontend pÃºblico

ğŸ”¹ ETAPA 12 â€” CI/CD + HARDENING

ğŸ“… Dias 46 a 50

CI/CD

Testes automatizados

Build de imagens

Push para registry

Deploy automÃ¡tico

Hardening

Resource requests / limits

Fail-fast

README final explicando decisÃµes

ğŸ RESULTADO ESPERADO

Ao final, vocÃª terÃ¡:

âœ”ï¸ Kubernetes real desde o inÃ­cio

âœ”ï¸ MicroserviÃ§os seguros

âœ”ï¸ Testes automatizados sÃ³lidos

âœ”ï¸ AWS prÃ¡tica

âœ”ï¸ CI/CD funcional

âœ”ï¸ Projeto nÃ­vel mercado

ğŸ”¥ NÃVEL DO EXERCÃCIO

ğŸ“ˆ Pleno forte â†’ SÃªnior inicial

## ğŸ“Š AvaliaÃ§Ã£o Final do ExercÃ­cio

### ğŸ”¹ Parte 0 â€” ARQUITETURA ORIENTADA A KUBERNETES 

**ExplicaÃ§Ã£o do aluno:**  

  Visao geral do sistema:

O sistema deve fazer autenticacao e autorizacao de usuarios. Endpoints para entender e usar a arquitetura com microsservicos e Kubernetes,
 alem de um frontend para entender de maneira mais proxima a realidade dos softwares em ambiente de producao e usados no mercado. 

Responsabilidades dos serviÃ§os:

eureka-server: todos os servicos irao se registrar no eureka-server, permitindo que os microservicos 
se encontrem dinamicamente sem depender de enderecos IP

config-server: as configuracoes ficarao centralizadas no config-server em um repositorio remoto, 
dessa forma centralizando todos os arquivos de configuracao/propriedades dos microservicos

api-gateway: ponto de entrada para os clientes acessarem os microservicos, serve tambem como 
load balance para o escalonamento dos microservicos com o Spring

auth-service: servico responsavel por autenticar os usuarios vindo das requisicoes 
do cliente 

user-service: servico responsavel pelo gerenciamento 
dos usuario (criacao, exclusao, alteracao dos usuarios)


Por que microserviÃ§os:
O uso de microservicos busca a separacao de responsabilidades no nÃ­vel de negocio e tambem 
na arquitetura. Facilitando o entendimento das regras de negocio e divisao das mesmas. Os microsservicos podem 
ser dividos por times por exemplo a medida que o projeto aumenta de tamanho e de dificuldades. 
Fornece deploy independente de outras partes do sistema, bem como tambem torna mais simplificada a evolucao do sistema e da 
    arquitetura como um todo, pois apenas esse servico e afetado por novas features ou correcoes de bugs.
Como trade-off os microservicos trazem desafios como a orquestracao via Kubernetes, observabilidade e 
automacao de deploy.

Separacao em dois bancos de dados (auth / user):
 Cada microservico possui seu proprio banco de dados, seguindo o prinicpio de autonomia dos microservicos. Essa separacao evita
 acoplametno direto, permite escalabilidade independente e melhora a seguranca ao separar dados sensiveis. 
 O time de autenticacao pode ser uma equipe mais madura, com menos restricoes de acesso enquanto o banco de cadastro de usuarios pode ser um pouco mais acessivel por exemplo.


Por que Kubernetes:
Os containers sao muito utilizados no mercado atual, principalmente usando praticas de DevOps, 
aonde automacao, observabilidade e facilidades para um deploy mais rapido sao essenciais. Neste
sentido o  Kubernetes vem como um orquestrador dos containers, permitindo escalonar a aplicacao
de forma rapida, tanto vertical com horizontalmente. Permite o monitoramento das aplicacoes com o uso de tecnicas de 
observabilidade entre outros. Kubernetes e utilizado desde o inicio do projeto como ambiente padrao de execucao, evitando
diferencas entre ambientes de desenvolvimento e producao.

Diagrama:

                               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                               â”‚        Kubernetes        â”‚
                               â”‚         Cluster          â”‚
                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                  Entrada Ãšnica (NodePort)
                                            â”‚
                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                   â”‚   svc-gateway    â”‚
                                   â”‚   (NodePort)     â”‚
                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚   pod-gateway   â”‚
                                    â”‚                â”‚
                                    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                                    â”‚ â”‚ api-gatewayâ”‚ â”‚
                                    â”‚ â”‚ Spring GW  â”‚ â”‚
                                    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                    â”‚      â”‚          â”‚
                                    â”‚      â–¼          â”‚
                                    â”‚  gateway-config â”‚ (ConfigMap)
                                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚                                                           â”‚A
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   svc-auth    â”‚                                      â”‚   svc-user    â”‚
        â”‚  (NodePort)  â”‚                                      â”‚  (NodePort)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                                                           â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚    pod-auth      â”‚                                     â”‚    pod-user      â”‚
      â”‚                 â”‚                                     â”‚                 â”‚
      â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                                     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
      â”‚ â”‚ auth-serviceâ”‚ â”‚                                     â”‚ â”‚ user-serviceâ”‚ â”‚
      â”‚ â”‚ Spring Boot â”‚ â”‚                                     â”‚ â”‚ Spring Boot â”‚ â”‚
      â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚                                     â”‚ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
      â”‚        â”‚         â”‚                                     â”‚        â”‚         â”‚
      â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                                     â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
      â”‚ â”‚  auth-db    â”‚ â”‚                                     â”‚ â”‚  user-db    â”‚ â”‚
      â”‚ â”‚ credentials â”‚ â”‚                                     â”‚ â”‚ user data  â”‚ â”‚
      â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                                     â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
      â”‚        â”‚         â”‚                                     â”‚        â”‚         â”‚
      â”‚   auth-config   â”‚ (ConfigMap)                          â”‚   user-config   â”‚ (ConfigMap)
      â”‚   auth-secrets  â”‚ (Secret)                             â”‚   user-secrets  â”‚ (Secret)
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜




**Nota do aluno:** `10/10`

**AnÃ¡lise do avaliador:**  
O projeto base foi criado corretamente utilizando o Spring Initializr, com Java 17 e estrutura padrÃ£o do Spring Boot. Apesar dos problemas iniciais relacionados ao Maven e Ã  diferenÃ§a de versÃµes do Java (Java 8 no sistema e Java 17 no projeto), o aluno demonstrou boa capacidade de diagnÃ³stico e resoluÃ§Ã£o de problemas de ambiente. A execuÃ§Ã£o do comando `mvn clean test` ocorreu com sucesso utilizando o Maven configurado pelo IntelliJ, validando que o projeto compila e que o contexto Spring sobe corretamente. A etapa atende completamente aos requisitos propostos.

Parte 1 â€” KUBERNETES LOCAL (BASE REAL)
ExplicaÃ§Ã£o do aluno

Para execuÃ§Ã£o da Parte 1 do exercÃ­cio, o ambiente Kubernetes foi configurado em um servidor Ubuntu, acessado remotamente via SSH, simulando um cenÃ¡rio mais prÃ³ximo de um ambiente real.

O objetivo desta etapa foi garantir que o cluster Kubernetes estivesse completamente funcional antes da implementaÃ§Ã£o de qualquer cÃ³digo de negÃ³cio, validando os conceitos fundamentais da plataforma.

ApÃ³s a configuraÃ§Ã£o do ambiente, foram executados os comandos definidos para esta etapa, conforme descrito abaixo.

**Nota do aluno:** `10/10`

AvaliaÃ§Ã£o do Avaliador
âœ… VisÃ£o geral da entrega

A Parte 1 do exercÃ­cio foi executada com sucesso, atendendo integralmente aos objetivos propostos.
O aluno demonstrou domÃ­nio prÃ¡tico do Kubernetes em ambiente real, utilizando um servidor Ubuntu acessado via SSH, o que aproxima a execuÃ§Ã£o de um cenÃ¡rio de produÃ§Ã£o e vai alÃ©m de ambientes puramente locais.

Todos os itens obrigatÃ³rios foram implementados, testados e comprovados por meio de comandos e saÃ­das reais.

ğŸ”¹ Ambiente Kubernetes

Ambiente Kubernetes configurado em servidor Ubuntu

Acesso realizado via SSH

Cluster operacional antes da implementaÃ§Ã£o de qualquer cÃ³digo de negÃ³cio

âœ” CritÃ©rio atendido

ğŸ”¹ Pods criados

O aluno criou dois Pods distintos:

nginx-pod â€” responsÃ¡vel por prover o serviÃ§o web

test-pod-ubuntu â€” utilizado como cliente interno para testes de conectividade e DNS

EvidÃªncia
kubectl get pods


SaÃ­da apresentada:

nginx-pod         1/1     Running
test-pod-ubuntu   1/1     Running


âœ” Demonstra entendimento de que Pod Ã© a unidade bÃ¡sica do Kubernetes, independente do container.

ğŸ”¹ Conceito: Pod â‰  Container

O comando:

kubectl describe pod nginx-pod


foi utilizado corretamente para demonstrar:

O Pod possui IP prÃ³prio

O container (nginx) estÃ¡ contido dentro do Pod

O ciclo de vida Ã© gerenciado pelo Kubernetes

Trechos relevantes analisados:

IP do Pod (10.42.0.13)

DefiniÃ§Ã£o explÃ­cita do container nginx

Estado Running sem reinicializaÃ§Ãµes

âœ” Conceito claramente demonstrado

ğŸ”¹ Services criados

Foram criados dois Services distintos apontando para o mesmo Pod, o que demonstra domÃ­nio da abstraÃ§Ã£o de rede do Kubernetes:

ClusterIP
clusterip-nginx   ClusterIP   10.43.72.56   80/TCP

NodePort
nodeport-nginx    NodePort    10.43.202.50   80:30080/TCP


âœ” O aluno demonstrou corretamente que:

Services nÃ£o sÃ£o IPs fixos de Pod

O Service abstrai o acesso ao Pod

Um mesmo Pod pode ser exposto por mÃºltiplos Services

ğŸ”¹ Conceito: Service â‰  IP fixo

A separaÃ§Ã£o entre Pod IP e Service IP foi evidenciada por:

IP do Pod: 10.42.0.13

IP do Service ClusterIP: 10.43.72.56

âœ” Demonstra entendimento de que:

O Service mantÃ©m estabilidade enquanto os Pods podem ser recriados com IPs diferentes.

ğŸ”¹ DNS interno do Kubernetes

O aluno comprovou o funcionamento do DNS interno utilizando:

nslookup clusterip-nginx


SaÃ­da analisada:

clusterip-nginx.default.svc.cluster.local
Address: 10.43.72.56


AlÃ©m disso, o acesso via nome do Service foi validado com sucesso:

curl clusterip-nginx


âœ” Demonstra domÃ­nio de:

DNS interno

Descoberta de serviÃ§os

ComunicaÃ§Ã£o entre Pods sem uso de IP direto

ğŸ”¹ Testes com kubectl exec

O comando foi utilizado corretamente para acessar o Pod cliente:

kubectl exec -it test-pod-ubuntu -- bash


âœ” Confirma acesso interativo ao container
âœ” Permitiu execuÃ§Ã£o de testes de rede internos

ğŸ”¹ Testes com kubectl logs

O comando:

kubectl logs nginx-pod


foi utilizado corretamente para:

Verificar inicializaÃ§Ã£o do nginx

Confirmar requisiÃ§Ãµes HTTP recebidas

Trechos importantes:

"GET / HTTP/1.1" 200


âœ” Demonstra rastreabilidade e observabilidade do Pod

ğŸ”¹ Testes com kubectl port-forward

O aluno utilizou corretamente:

kubectl port-forward pod/nginx-pod 7070:80


E validou o acesso externo local:

curl localhost:7070


âœ” Demonstra entendimento de:

Encaminhamento direto para Pod

Acesso sem necessidade de Service externo

ğŸ”¹ NodePort (acesso externo)

O Service NodePort foi validado corretamente:

kubectl get svc nodeport-nginx


SaÃ­da:

80:30080/TCP


âœ” Demonstra entendimento de exposiÃ§Ã£o externa do serviÃ§o via porta do nÃ³

ğŸ“Œ AvaliaÃ§Ã£o Final da Parte 1
CritÃ©rio	Status
Cluster Kubernetes funcional	âœ…
Pod nginx criado	âœ…
Pod cliente para testes	âœ…
Service ClusterIP	âœ…
Service NodePort	âœ…
DNS interno validado	âœ…
kubectl exec	âœ…
kubectl logs	âœ…
kubectl describe	âœ…
kubectl port-forward	âœ…
Conceitos explicados na prÃ¡tica	âœ…
ğŸ ConclusÃ£o do Avaliador

A Parte 1 foi executada de forma completa e correta, com excelente nÃ­vel tÃ©cnico para a etapa proposta.
O aluno demonstrou nÃ£o apenas execuÃ§Ã£o de comandos, mas compreensÃ£o dos conceitos fundamentais do Kubernetes, especialmente rede, abstraÃ§Ã£o de serviÃ§os e diagnÃ³stico


Parte 2 â€”

Configuracao do Spring Boot Actuator: o Spring Boot Actuator e o modulo de observabilidade e operacao do Spring Boot.
Este fornece endpoints operacionais como /actuator/health que responde com UP/DOWN e tambem possue endpoints de metricas
- /actuator/metrics - que traz informacoes como quantas requisiÃ§Ãµes, tempo mÃ©dio, erros, Status HTTP.
Tambem possue o endpoint /actuator/info que tras informacoes gerais como versÃ£o, nome, build.

